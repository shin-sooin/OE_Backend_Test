import numpy as np
from collections import Counter
import pyocr
from PIL import Image
from ultralytics import YOLO
import cv2
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'



class Model():
    def __init__(self):
        self.info = ""
        self.summary = ""
        self.error = ""
        
        return
    
    
    def modeling(self, mode, path_dlocal, path_ulocal):
        # image open
        try:
            self.img = np.asarray(Image.open(path_dlocal))
        except:
            self.error = 'please check url of image'
            return
        
        if mode == 0:
            self.object()
        
        if mode == 1:
            self.ocr()
            # self.summarize()
        
        # store model image
        self.path_ulocal = path_ulocal
        cv2.imwrite(self.path_ulocal, self.img)
        
        return self.info, self.summary, self.error
    
    
    def object(self):
        model = YOLO("yolov8n.pt")
        
        obj_results = model(self.img, device="mps")
        obj_result = obj_results[0]
        
        bboxes = np.array(obj_result.xyxy.cpu(), dtype="int")
        
        for bbox in bboxes:
            (x, y, x2, y2) = bbox
            cv2.rectangle(self.img, (x, y), (x2, y2), (0, 0, 255), 2)
        
        classes = np.array(obj_results.boxes.cls.cpu(), dtype="int")
        class_list = []
        for i in range(len(classes)):
            class_list.append(model.namespint(classes[i]))
        
        self.info = dict(Counter(class_list))        
        
        return
    
    
    def ocr(self):
        tools = pyocr.get_available_tools()
        if len(tools) == 0:
            self.error = "OCR tool is not found"
            return
        
        tool = tools[0]
        wk_builder = pyocr.builders.WordBoxBuilder()
        ocr_results = tool.image_to_string(
            self.img,
            lang = "kor+eng",
            builder=wk_builder
        )
        
        editor = []
        before_position = 0
        for ocr_result in ocr_results:
            print(ocr_result.position)
            if ocr_result.position[1][1] - before_position > 30:
                before_position = ocr_result.position[1][1]
                editor.append('\n')
            editor.append(ocr_result.content)
            cv2.rectangle(self.img, ocr_result.position[0], ocr_result.position[1], (0, 255, 255), 1)
        
        self.info = editor
        
        return
    
    
    # def summarize(self):
    #     with open('openai_key.txt', 'r') as f:
    #         api_key = f.read().strip()
        
    #     openai.api_key = api_key
        
    #     """
    #     Summarize the input text using the OpenAI GPT-3 API.
    #     Args:
    #     text (str): Input text to be summarized.
    #     Returns:
    #     summary (str): Summary of the input text generated by the API.
    #     """
    #     # Use the GPT-3 "davinci" model for summarization
    #     model_engine = "davinci"

    #     # Set the prompt for the API request
    #     prompt = (f"Please summarize the following text:\n"
    #               f"{self.info}\n"
    #               f"Summary:")

    #     # Call the OpenAI API to generate a summary
    #     response = openai.Completion.create(
    #         engine=model_engine,
    #         prompt=prompt,
    #         max_tokens=60,
    #         n=1,
    #         stop=None,
    #         temperature=0.7,
    #     )

    #     # Extract the summary from the API response
    #     self.summary = response.choices[0].text.strip()

    #     return